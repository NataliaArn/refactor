# MDN Learn task refactoring and unit testing: task instructions

## Refactoring and Unit Testing

- We are refactoring the MDN Conditionals 2 task done earlier.
- [Code refactoring](https://en.wikipedia.org/wiki/Code_refactoring) means
  reimplementing an existing (and working) code, but preserving its
  functionality.
  - Its external behaviour remains unchanged, but internally we are
    improving things as the design, structure and/or implementation (its
    non-functional attributes).
  - The purpose for doing can be:
    - Improve maintainability and/or extensibility (by improving readability and
      reducing complexity).
    - And/or improve performance (less use of ressources, e.g. speed and/or
      memory).
- [Code refactoring and automatic UT (unit testing)](https://en.wikipedia.org/wiki/Code_refactoring#Testing)
  are quite related. They come hand-with-hand in Agile development
  methodologies.
- Normally, we do the UT before refactoring, but in our case the starting point
  does not permit easily an external UT.
- So we are performing a first refactoring just to be able to implement a
  UT: our first refactoring will be to wrap the significant code in a
  function and place it at an external JS.
- **Note**: see at the end the final overal files structure expected.

## Task steps

1. Copy your file `02-conditionals/conditionals2-download.html` from the
   previous task to the root of this task:

   `conditionals2-download.html`

   Note: files structure at the end of this task will be:

   ```text
   conditionals2-download.html
   scripts/get-response/
     main.js
     main-fix.js
     main-ternary.js
     main-ternary-all.js
     main-switch.js
     uts.js
     uts.html
   ```

   Although some of these files are optional/bonus (see details next).

2. Create a file `scripts/get-response/main.js` that contains the
   declaration of a function:

   `getResponse()`

   that gets two parameters:

   - The score.
   - Whether the machine is active or not.

   Inside its body, move the code (from the copy
   `conditionals2-download.html`), that generates the response message (by
   checking the machine status and the score).

   The function returns the generated message.

3. Since we've removed that code from inside `conditionals2-download.html`,
   go to that file and modify it so that it works again:

   - Before the script element, load the external script so that the
     `getResponse()` function is available in the global scope.
   - Now, call that function in the right place to obtain the response that
     will be later used in the place we don't have to touch the code.

4. Test that it works as before refactoring.

5. Now we are going to prepare the UT for `getResponse()`: since it is in an
   external file now, we can create a separate .html that loads it, and does
   the UT on it (and we leave the original .html unaffected by the UT).

   Under `scripts/get-response/`, create these two files:

   - A file `uts.js`: contains a unique function declaration `uts()`,
     without parameters. For the momment, leave its body empty.
   - A file `uts.html`:
     - Start with a minimalistic HTML template generated by Emmet, with
       title "UT: getResponse()".
     - In its body, it loads external files `ut.js` then `main.js`
     - Then, it logs this delimiter string:

       `## UT: getResponse() original`

       followed by an empty line.

     - Then, it executes `uts()` function (currently empty).

6. Test that `uts.html` works for now as expected (logs its stuff, has no
   errors).

7. Let's implement `uts()`:
   - It will perform a series of UT's and show info on the console regarding
     the obtained result for each one.
   - Each UT consists in calling the function `getResponse()` with some
     parameter values, and logging somehow if it worked as expected.
   - The `uts()` should log something like this (explanation below):

     ```text
     testNum | Pass/Fail | score | machineActive [| expectedResponse | response]
     ---
     1 | Pass | 75 | false
     2 | Pass | 75 | true
     3 | Pass | 150 | true
     ---
     Fails: 0
     ```

   - That is:
     - It logs a static first line acting as a legend for the different fields
       that will have the lines below (four fields, plus two optional ones).
     - It logs a delimiter '---'.
     - It then logs the result of each test, the result of one test per each
       line. In each line, ` | ` delimits the different fields.
     - In each line, it shows:
       - The test number (starts with 1, then increases for each test).
       - "Pass" if the response returned by the function is the expected one
         for these input parameters.
       - The 2 particular input parameter values used for that test.
     - After the tests, it logs a delimiter '---'.
     - Then it logs a summary of the number of failed tests:
       - "Fails: ", followed by that number (0 in this example).
   - For the momment, we are just doing these 3 particular tests shown.
   - But the UT's should log "Fail" instead of "Pass" if the response is
     different from the one expected for these input parameters. In this
     case, it should also log the expected response and the actual response
     (for helping on debugging).
   - For example, imagine that the implementation of `getResponse()`:
     - Has forgotten to use the parameter that indicates if the machine is
       active.
     - Has forgotten to check for values exceeding 100.

     In this case, with the previous 3 tests applied to that implementation,
     we should get:

     ```text
     testNum, Pass/Fail, score, machineActive [, expectedResponse, response]
     ---
     1 | Fail | 75 | false | Please switch the machine on. | That\'s a great score, you really know your stuff.
     2 | Pass | 75 | true
     3 | Pass | 150 | false | This is not possible, an error has occurred. | What an amazing score! Did you cheat? Are you for real?
     ---
     Fails: 2
     ```

     Note that the final "Fails:" shows in this summary that 2 tests failed.

8. Load the `uts.html`, and verify if the 3 tests pass or not. Don't fix for
   now the `getResponse()` code inside `scripts/get-response/main.js`. Just
   test your implementation.

9. Copy `scripts/get-response/main.js` to `scripts/get-response/main-fix.js`.

   We are going to pass the `uts()` function to that new implementation, and
   make any needed fix there (not in the original).

   For this, edit `uts.html` and at the end (before the body closing tag),
   **add** the following (without removing or commenting what you already
   have):

   - Load `main-fix.js`
   - Then, log this delimiter string:

     `## UT: getResponse() fixed`

     followed by an empty line.

   - Then, execute `uts()` function.
   - Note: loading `main-fix.js` will override the previous declaration of
     `getResponse()` that came from loading `main.js` earlier. The first `uts()`
     execution acts on the first implementation, the second one acts on the
     second implementation. This may not be a good practice sometimes, but
     we do it here for demostrative purposes of JS behaviour (global single
     scope, runtime overriding of function declarations, ...).

10. Fix the code of `main-fix.js` in case that some of the 3 tests did not
    pass in the original implemantation.
    Load `uts.html`, and verify that the tests battery passes for
    "getResponse() fixed". Check also that we still get before the block of
    the test battery for "getResponse() original".

11. Now that we have made 3 unit tests (less than nothing), let's make some
    more:

    Try to cover as much as possible the different cases we may have.

    Now that you are increasing the number of tests, do not hesitate to
    refactor your `uts()` implementation so that it is more mantainable:
    reduce repeated code (using functions, variables, etc, when pertinent).

    When designing the test use cases, imagine that the score (input
    parameter for the function), in production is obtained directly from the
    user (with `prompt()`). On the other hand, the state of the machine is
    known (obtained) from inside our code.

    Bonus: to follow good practices, if you create for example a function for
    facilitating the writing of more tests, try to encapsulate: avoid to use
    external variables (global) inside a function, declare the function in
    the scope where it is needed.

12. Load the `uts.html`, and verify that your tests pass. Try to fix in
    `main-fix.js` any one that does not pass.

13. Now that we have done this work let's benefit from it. Imagine that you
    want to refactor the `getResponse()` implementation so that it uses
    ternary operators when checking the score, instead of if/elseifs.

    Copy `main-fix.js` to `main-ternary.js`

    Edit `uts.html` and at the end (before the body closing tag),
    **add** the following (without removing or commenting what you already
    have):

    - Load `main-ternary.js`
    - Then, log this delimiter string:

      `## UT: getResponse() refactored with ternary for score`

      followed by an empty line.

    - Then, execute `uts()` function.

    Then, refactor the `getResponse()` implementation inside
    `main-ternary.js`, and check with `uts.html` that you are not breaking
    anything.

14. Bonus: like previous step, but let's try another implementation.

    Copy `main-ternary.js` to `main-ternary-all.js`, and refactor the
    ternary implementation so that it uses also ternary for checking the
    machine state. The body of the `getResponse()` function will be a single
    "return" statement, that has a unique (complex) expression that expands
    to the expected response (by using combined ternaries).

    In `uts.html`, add the loading and testing of this implementation at the
    end, with delimiting text:

      `## UT: getResponse() refactored with all ternaries`

    Note: it is not clear that this refactoring is a good practice. But
    since we have our UT battery, we can have fun and refactor, play,
    explore, with the safety net of the regression testing.  If we break
    something, we will know it. If something behaves differently, we will
    know it. The more complete the UT battery, the more safety net that we
    have.

15. Bonus: like previous step, but let's try yet another implementation.

    Copy `main-fixed.js` to `main-switch.js`, and refactor the
    score check so that it uses a `switch` statement instead of a chain of
    if/elseif's.

    In `uts.html`, add the loading and testing of this implementation at the
    end, with delimiting text:

      `## UT: getResponse() refactored with a switch`

    Note: Don't be surprised if after thingking, you need to Google for some
    "inspiration" for doing this implementation. It requires a hacky use of
    `switch()`, that for sure is a **bad** practice. But, hey! We are having
    fun here, with our safety net. Our bad implementation is encapsulated in
    a function... if it passes our test battery, it is at least doing its
    job.

- Note: the more complete your test battery is, the less perfect you can
  affort beeing when programming. A good test battery overcomes other
  limitations and difficulties, and makes you provide a code with assured
  quality in its lifetime of fixes and refactoring.

- Final note: in this exercise, `getResponse()` does not use at all any of
  the Web APIs. That means that we could have avoided testing from an html,
  and do it directly from a .js, loaded and executed with node. We could
  then process the output with a script (node script or bash script),
  instead of having to look to the console in a browser... This allows to
  further automatize the UT: ckecking that it globally passes without fails,
  and only warn otherwhise... So this would scale very well: a battery of
  batteries of UT's for the different functions in the project. They are
  quite silent unless something is unexpected. Time and energy spent to do
  regression test (once it has been prepared)? Less than 1 second, less than
  1 calorie. Always remember the [3 virtues of great a programmer](https://thethreevirtues.com/).

## Deliver

- Put your produced files with the expected structure **directly under the
  root** of a ZIP file named:

  `first-surname.name.mdn-js-refactor.zip`

  - Use only ascii characters and kebab-case in the file name:
    - E.g. José Luís NÚÑEZ CLEMENTE will give:

      `nunez.jose-luis.mdn-js-refactor.zip`

  - Put **only** the requested files. If you have to comment something
    or add something extra:
    - Comment internally to the files.
    - If not enough, you can use a `readme.md` (all lowercase) in the root,
      and mention there anything extra or files/folders not expected.
  - Deliver the ZIP file in the medium indicated by the teacher.
